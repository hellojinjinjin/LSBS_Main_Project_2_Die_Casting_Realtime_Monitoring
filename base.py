#######################################################
# ëª°íŠ¼ íƒ¬í”„ ë

import pandas as pd
import plotly.graph_objects as go
from pykalman import KalmanFilter

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
train = pd.read_csv('./data/train.csv')

# tryshot_signal D â†’ 1, ì•„ë‹ˆë©´ 0
train['tryshot_signal_D'] = train['tryshot_signal'].apply(lambda x: 1 if x == 'D' else 0)

# real_time â†’ datetime
train['real_time'] = pd.to_datetime(train['real_time'])

# ê²°ì¸¡ê°’ ì—¬ë¶€
train['is_nan'] = train['molten_temp'].isna()

# Kalman Filter ì ìš©
kf = KalmanFilter(
    transition_matrices=[1],
    observation_matrices=[1],
    initial_state_mean=train['molten_temp'].dropna().iloc[0],
    observation_covariance=1,
    transition_covariance=0.1
)
state_means, _ = kf.filter(train['molten_temp'].fillna(method='ffill').values)
train['molten_temp_kf'] = state_means.flatten()

# ìŠ¤ë¬´ì‹±
train['molten_temp_kf_smooth'] = train['molten_temp_kf'].rolling(window=10, min_periods=1).mean()

# ì‹œê°í™”
fig = go.Figure()

# KF ë³´ì • ì„  (ì§„í•œ ë¹¨ê°•)
fig.add_trace(go.Scatter(
    x=train['real_time'],
    y=train['molten_temp_kf'],
    mode='lines',
    name='Kalman Filtered',
    line=dict(color='#b30000', width=2.5)
))

# ìŠ¤ë¬´ì‹± ì„  (ì§„í•œ ê²€ì •)
fig.add_trace(go.Scatter(
    x=train['real_time'],
    y=train['molten_temp_kf_smooth'],
    mode='lines',
    name='Smoothed (Rolling 10)',
    line=dict(color='black', width=2.5)
))

# passorfail=1 ì  (ì—°í•œ ë¹¨ê°•)
fig.add_trace(go.Scatter(
    x=train.loc[train['passorfail']==1, 'real_time'],
    y=train.loc[train['passorfail']==1, 'molten_temp_kf'],
    mode='markers',
    name='passorfail=1',
    marker=dict(color='#ff9999', size=6, opacity=0.7)
))

# passorfail=0 ì  (ì—°í•œ íŒŒë‘)
fig.add_trace(go.Scatter(
    x=train.loc[train['passorfail']==0, 'real_time'],
    y=train.loc[train['passorfail']==0, 'molten_temp_kf'],
    mode='markers',
    name='passorfail=0',
    marker=dict(color='#99ccff', size=6, opacity=0.7)
))

# ê²°ì¸¡ê°’ ìœ„ì¹˜ X ë§ˆì»¤ (ê²€ì •)
fig.add_trace(go.Scatter(
    x=train.loc[train['is_nan'], 'real_time'],
    y=train.loc[train['is_nan'], 'molten_temp_kf'],
    mode='markers',
    name='NaN',
    marker=dict(color='black', size=6, symbol='x', opacity=0.9)
))

# tryshot_signal D ì  (ì´ˆë¡)
fig.add_trace(go.Scatter(
    x=train.loc[train['tryshot_signal_D']==1, 'real_time'],
    y=train.loc[train['tryshot_signal_D']==1, 'molten_temp_kf'],
    mode='markers',
    name='tryshot_signal=D',
    marker=dict(color='green', size=5, opacity=0.7)
))

fig.update_layout(
    title='Molten Temp: KF + Smoothed with passorfail and NaN Highlighted',
    xaxis_title='Real Time',
    yaxis_title='Molten Temperature',
    template='plotly_white',
    height=600
)

fig.show()




##################################################################
train.isna().sum()

import pandas as pd
import plotly.graph_objects as go

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
train = pd.read_csv('./data/train.csv')

# real_time â†’ datetime
train['real_time'] = pd.to_datetime(train['real_time'])

# ê²°ì¸¡ê°’ ì—¬ë¶€
train['is_nan'] = train['low_section_speed'].isna()

# ì‹œê³„ì—´ ë¼ì¸
fig = go.Figure()

# ì›ë³¸ ì‹œê³„ì—´ ì„ 
fig.add_trace(go.Scatter(
    x=train['real_time'],
    y=train['low_section_speed'],
    mode='lines+markers',
    name='low_section_speed',
    line=dict(color='#1f77b4', width=2),
    marker=dict(size=4, opacity=0.7)
))

# ê²°ì¸¡ê°’ X í‘œì‹œ
fig.add_trace(go.Scatter(
    x=train.loc[train['is_nan'], 'real_time'],
    y=[0]*train['is_nan'].sum(),  # ì‹œê°ì ìœ¼ë¡œ 0 ìœ„ì¹˜
    mode='markers',
    name='Missing Value',
    marker=dict(color='red', size=6, symbol='x', opacity=0.9)
))

fig.update_layout(
    title='Low Section Speed over Time',
    xaxis_title='Real Time',
    yaxis_title='Low Section Speed',
    template='plotly_white',
    height=500
)

fig.show()
train.isna().sum()


#################################################################################

import pandas as pd
import plotly.graph_objects as go
from pykalman import KalmanFilter

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
train = pd.read_csv('./data/train.csv')

# tryshot_signal D â†’ 1, ì•„ë‹ˆë©´ 0
train['tryshot_signal_D'] = train['tryshot_signal'].apply(lambda x: 1 if x == 'D' else 0)

# real_time â†’ datetime
train['real_time'] = pd.to_datetime(train['real_time'])

# molten_volume ê²°ì¸¡ ì—¬ë¶€
train['is_nan_volume'] = train['molten_volume'].isna()

# Kalman Filter ì ìš©
kf_volume = KalmanFilter(
    transition_matrices=[1],
    observation_matrices=[1],
    initial_state_mean=train['molten_volume'].dropna().iloc[0],
    observation_covariance=1,
    transition_covariance=0.1
)
state_means_vol, _ = kf_volume.filter(train['molten_volume'].fillna(method='ffill').values)
train['molten_volume_kf'] = state_means_vol.flatten()

# ìŠ¤ë¬´ì‹±
train['molten_volume_kf_smooth'] = train['molten_volume_kf'].rolling(window=10, min_periods=1).mean()

# ì‹œê°í™”
fig = go.Figure()

# KF ë³´ì • ì„  (ì§„í•œ ë¹¨ê°•)
fig.add_trace(go.Scatter(
    x=train['real_time'],
    y=train['molten_volume_kf'],
    mode='lines',
    name='Kalman Filtered',
    line=dict(color='#b30000', width=2.5)
))

# ìŠ¤ë¬´ì‹± ì„  (ì§„í•œ ê²€ì •)
fig.add_trace(go.Scatter(
    x=train['real_time'],
    y=train['molten_volume_kf_smooth'],
    mode='lines',
    name='Smoothed (Rolling 10)',
    line=dict(color='black', width=2.5)
))

# passorfail=1 ì  (ì—°í•œ ë¹¨ê°•)
fig.add_trace(go.Scatter(
    x=train.loc[train['passorfail']==1, 'real_time'],
    y=train.loc[train['passorfail']==1, 'molten_volume_kf'],
    mode='markers',
    name='passorfail=1',
    marker=dict(color='#ff9999', size=6, opacity=0.7)
))

# passorfail=0 ì  (ì—°í•œ íŒŒë‘)
fig.add_trace(go.Scatter(
    x=train.loc[train['passorfail']==0, 'real_time'],
    y=train.loc[train['passorfail']==0, 'molten_volume_kf'],
    mode='markers',
    name='passorfail=0',
    marker=dict(color='#99ccff', size=6, opacity=0.7)
))

# ê²°ì¸¡ê°’ ìœ„ì¹˜ X ë§ˆì»¤ (ê²€ì •)
fig.add_trace(go.Scatter(
    x=train.loc[train['is_nan_volume'], 'real_time'],
    y=train.loc[train['is_nan_volume'], 'molten_volume_kf'],
    mode='markers',
    name='NaN',
    marker=dict(color='black', size=6, symbol='x', opacity=0.9)
))

# tryshot_signal D ì  (ì´ˆë¡)
fig.add_trace(go.Scatter(
    x=train.loc[train['tryshot_signal_D']==1, 'real_time'],
    y=train.loc[train['tryshot_signal_D']==1, 'molten_volume_kf'],
    mode='markers',
    name='tryshot_signal=D',
    marker=dict(color='green', size=5, opacity=0.7)
))

fig.update_layout(
    title='Molten Volume: KF + Smoothed with passorfail and NaN Highlighted',
    xaxis_title='Real Time',
    yaxis_title='Molten Volume',
    template='plotly_white',
    height=600
)

fig.show()

#################################################################

import numpy as np
import pandas as pd
from pykalman import KalmanFilter

# 1ï¸âƒ£ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('./data/train.csv')

# 2ï¸âƒ£ KFë¡œ ê²°ì¸¡ì¹˜ ì±„ìš¸ ì¹¼ëŸ¼
kf_columns = ['molten_temp', 'molten_volume', 'upper_mold_temp3']

# 3ï¸âƒ£ ê° ì¹¼ëŸ¼ë§ˆë‹¤ KF ì ìš© í›„ ë°”ë¡œ ê¸°ì¡´ ì¹¼ëŸ¼ì— ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°
for col in kf_columns:
    if col in df.columns:
        kf = KalmanFilter(
            transition_matrices=[1],
            observation_matrices=[1],
            initial_state_mean=df[col].dropna().iloc[0],
            observation_covariance=1,
            transition_covariance=0.1
        )
        state_means, _ = kf.filter(df[col].fillna(method='ffill').values)
        mask = df[col].isna()
        df.loc[mask, col] = state_means.flatten()[mask]

# 4ï¸âƒ£ ì‚­ì œí•  ì¹¼ëŸ¼ë§Œ ì œê±°
if 'lower_mold_temp3' in df.columns:
    df = df.drop(columns=['lower_mold_temp3'])


df.isna().sum()

df.dropna(subset= 'working', inplace=True)

# 5ï¸âƒ£ CSV ì €ì¥
df.to_csv('./data/train_res.csv', index=False)

print("âœ… KFë¡œ ê²°ì¸¡ì¹˜ ë°”ë¡œ ì±„ìš°ê³ , lower_mold_temp3ë§Œ ì œê±° ì™„ë£Œ, train_res.csv ì €ì¥ë¨")


####################################################################################################################
# ëª¨ë¸ êµ¬í˜„ ë° ì €ì¥


# íŒŒìƒ ë³€ìˆ˜ ë§Œë“¤ê¸° íŒŒíŠ¸ ì£¼ì•¼ shift  global_count  monthly_count  speed_ratio  pressure_speed_ratio real_time

#######################################################################################################################
## ì¸ì½”ë”©

import numpy as np
import pandas as pd
from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder

train = pd.read_csv('./data/fin_train.csv')
test = pd.read_csv('./data/fin_test_kf.csv')

train

# ì˜ˆì‹œ ì»¬ëŸ¼
label_cols = ["working", "emergency_stop", "tryshot_signal", "shift"]
onehot_cols = ["mold_code", "heating_furnace"]

# -------------------------------
# 1ï¸âƒ£ tryshot_signal ê²°ì¸¡ì¹˜ ì²˜ë¦¬
# -------------------------------
# ìµœë¹ˆê°’ìœ¼ë¡œ ì±„ìš°ê¸° (ë¬¸ìí˜• 'D' í¬í•¨ ê°€ëŠ¥)
# tryshot_signal ì´ì§„í™”: D=1, ê·¸ ì™¸=0
df['tryshot_signal'] = df['tryshot_signal'].apply(lambda x: 1 if x == 'D' else 0)


# -------------------------------
# 2ï¸âƒ£ Label ì¸ì½”ë”© ëŒ€ì²´ (OrdinalEncoder)
# -------------------------------
# handle_unknown ì˜µì…˜ìœ¼ë¡œ ìƒˆë¡œìš´ ê°’ë„ í—ˆìš©
ordinal = OrdinalEncoder(handle_unknown="use_encoded_value", unknown_value=-1)
df[label_cols] = ordinal.fit_transform(df[label_cols])

# -------------------------------
# 3ï¸âƒ£ One-hot ì¸ì½”ë”©
# -------------------------------
# handle_unknown='ignore'ë¡œ ìƒˆë¡œìš´ ê°’ ë¬´ì‹œ
onehot = OneHotEncoder(handle_unknown="ignore", sparse_output=False)
encoded = onehot.fit_transform(df[onehot_cols])

# ì»¬ëŸ¼ëª… ë³µì›
encoded_cols = onehot.get_feature_names_out(onehot_cols)
encoded_df = pd.DataFrame(encoded, columns=encoded_cols, index=df.index)

# ê¸°ì¡´ dfì™€ ê²°í•©
df = pd.concat([df.drop(columns=onehot_cols), encoded_df], axis=1)

# -------------------------------
# 4ï¸âƒ£ speed_ratio ì²˜ë¦¬
# -------------------------------
# inf ê°’ ì²˜ë¦¬
df.loc[df["speed_ratio"] == float("inf"), "speed_ratio"] = -1
# low_section_speed, high_section_speed ë‘˜ ë‹¤ 0ì¼ ê²½ìš° ì²˜ë¦¬
df.loc[(df["low_section_speed"] == 0) & (df["high_section_speed"] == 0), "speed_ratio"] = -2

# pressure_speed_ratioê°€ inf ë˜ëŠ” -infì´ë©´ -1ë¡œ ëŒ€ì²´
df.loc[np.isinf(df["pressure_speed_ratio"]), "pressure_speed_ratio"] = -1

df.isna().sum()

'''
team ì´ë‘ real_time ì€ ëº´ê³  í•™ìŠµì„ ëŒë¦´ì˜ˆì • íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ í•´ì•¼í•˜ê³  threshold ë„ íŒŒë¼ë¯¸í„°ë¥¼ ì •í•´ì„œ ê³¨ë¼ì•¼í•˜ê³  SMOTE NCë¡œ í•´ì•¼í• ê±°ê°™ìœ¼ë©´ SMOTE NCë¡œ ì•„ë‹Œê±° ê°™ìœ¼ë©´ SMOTE ë‘˜ì¤‘í•˜ë‚˜ë¡œ í•´ì£¼ê³  ì–¼ë§ˆë‚˜ ëŠ˜ë ¤ì•¼í•˜ëŠ”ì§€
XG ë¶€ìŠ¤íŠ¸ë„ í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ì„ ëª¨ë“ ê²ƒì„ ë‹¤í•´ì£¼ê³  ì´ê±¸ ì˜µíŠœë‚˜ì— ë² ì´ì§€ì•ˆ ì •ë¦¬ë¥¼ í•´ì„œ í•´ì¤¬ìœ¼ë©´ ì¢‹ê² ì–´ ê·¸ë¦¬ê³  cvë„ íŠœë‹ë‹¤í•´ì¤˜ ë¨¸ê°€ ì¢‹ì€ì§€ ê·¸ë¦¬ê³  íƒ€ê²Ÿì€ passorfail ì´ê³  test ë°ì´í„°ì—ë„ ì´ê²Œ ìˆì–´ ë‘˜ë‹¤ ëº´ë†“ê³  í•´ì•¼í•˜ê³  testëŠ” ì¼ë‹¨ ì‚¬ìš©í•˜ì§€ë§ê³ 
trainë°ì´í„°ë§Œ ë‚˜ëˆˆë‹¤ìŒ í™•ì¸í•´ì£¼ê³  testë°ì´í„°ëŠ” ë‚˜ì¤‘ì— ì§„í–‰í•  ì˜ˆì •ì´ë‹ˆê¹Œ ê±´ë“¤ì§€ ë§ì•„ì£¼ê³  test ë°ì´í„°ì— ë°”ë¡œ ì‚¬ìš©í• ìˆ˜ ìˆê²Œ í”¼í´ë¡œ ì €ì¥í•´ì„œ ì‚¬ìš©í• ìˆ˜ ìˆê²Œ íŒŒì´í”„ë¼ì¸ì„ ë§Œë“¤ì–´ì¤˜

'''



##################################################################################


# fin_xgb_pipeline_f2_optuna_full.py
import os
import json
import warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd

from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import fbeta_score
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, FunctionTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline

import optuna
from tqdm import tqdm
from xgboost import XGBClassifier
import joblib

# -------------------------------
# 0ï¸âƒ£ ë°ì´í„° ë¡œë“œ
# -------------------------------
train = pd.read_csv('./data/fin_train.csv')
test = pd.read_csv('./data/fin_test_kf.csv')  # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ

TARGET = 'passorfail'
DROP_COLS = ['team', 'real_time']

label_cols = ["working", "emergency_stop", "tryshot_signal", "shift"]
onehot_cols = ["mold_code", "heating_furnace"]

# -------------------------------
# 1ï¸âƒ£ ê·œì¹™ ê¸°ë°˜ ì „ì²˜ë¦¬ í•¨ìˆ˜
# -------------------------------
def basic_fix(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    if 'tryshot_signal' in df.columns:
        df['tryshot_signal'] = df['tryshot_signal'].apply(lambda x: 1 if x == 'D' else 0)

    if {'speed_ratio', 'low_section_speed', 'high_section_speed'} <= set(df.columns):
        df.loc[df["speed_ratio"] == float("inf"), "speed_ratio"] = -1
        df.loc[df["speed_ratio"] == -float("inf"), "speed_ratio"] = -1
        df.loc[(df["low_section_speed"] == 0) & (df["high_section_speed"] == 0), "speed_ratio"] = -2

    if 'pressure_speed_ratio' in df.columns:
        df.loc[np.isinf(df["pressure_speed_ratio"]), "pressure_speed_ratio"] = -1

    return df

feature_fixer = FunctionTransformer(basic_fix, validate=False)

# -------------------------------
# 2ï¸âƒ£ ë°ì´í„° ë¶„ë¦¬
# -------------------------------
y = train[TARGET].values
X_raw = train.drop(columns=[TARGET] + [c for c in DROP_COLS if c in train.columns])

label_cols_eff = [c for c in label_cols if c in X_raw.columns]
onehot_cols_eff = [c for c in onehot_cols if c in X_raw.columns]
num_cols_eff = [c for c in X_raw.columns if c not in set(label_cols_eff + onehot_cols_eff)]

# -------------------------------
# 3ï¸âƒ£ ColumnTransformer ì„¤ì •
# -------------------------------
ct = ColumnTransformer(
    transformers=[
        ("label_enc", Pipeline([
            ("impute", SimpleImputer(strategy="most_frequent")),
            ("ord", OrdinalEncoder(handle_unknown="use_encoded_value", unknown_value=-1)),
        ]), label_cols_eff),

        ("onehot", Pipeline([
            ("impute", SimpleImputer(strategy="most_frequent")),
            ("oh", OneHotEncoder(handle_unknown="ignore", sparse_output=False)),
        ]), onehot_cols_eff),

        ("num", SimpleImputer(strategy="median"), num_cols_eff),
    ],
    remainder="drop",
    verbose_feature_names_out=False,
)

# -------------------------------
# 4ï¸âƒ£ XGBoost ìƒì„± í•¨ìˆ˜
# -------------------------------
def make_clf(params: dict) -> XGBClassifier:
    return XGBClassifier(
        n_estimators=params.get("n_estimators", 400),
        max_depth=params.get("max_depth", 6),
        learning_rate=params.get("learning_rate", 0.05),
        subsample=params.get("subsample", 0.8),
        colsample_bytree=params.get("colsample_bytree", 0.8),
        min_child_weight=params.get("min_child_weight", 1.0),
        gamma=params.get("gamma", 0.0),
        scale_pos_weight=params.get("scale_pos_weight", 1.0),
        reg_lambda=params.get("reg_lambda", 1.0),
        reg_alpha=params.get("reg_alpha", 0.0),
        max_delta_step=params.get("max_delta_step", 0.0),
        random_state=42,
        n_jobs=-1,
        eval_metric="logloss",
        use_label_encoder=False
    )

# -------------------------------
# 5ï¸âƒ£ Optuna Objective (F2-score)
# -------------------------------
def objective(trial):
    params = {
        "n_estimators": trial.suggest_int("n_estimators", 200, 1000),
        "max_depth": trial.suggest_int("max_depth", 3, 12),
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3, log=True),
        "subsample": trial.suggest_float("subsample", 0.5, 1.0),
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.5, 1.0),
        "min_child_weight": trial.suggest_float("min_child_weight", 0.1, 10.0),
        "gamma": trial.suggest_float("gamma", 0.0, 5.0),
        "scale_pos_weight": trial.suggest_float("scale_pos_weight", 0.5, 10.0),
        "reg_lambda": trial.suggest_float("reg_lambda", 0.0, 10.0),
        "reg_alpha": trial.suggest_float("reg_alpha", 0.0, 10.0),
        "max_delta_step": trial.suggest_float("max_delta_step", 0.0, 10.0),
    }

    threshold = trial.suggest_float("threshold", 0.05, 0.95)

    clf = make_clf(params)

    # íŒŒì´í”„ë¼ì¸ì— XGB í¬í•¨
    pipe = ImbPipeline(steps=[
        ("fix", feature_fixer),
        ("ct", ct),
        ("smote", SMOTE(random_state=42)),
        ("clf", clf)
    ])

    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    f2_scores = []

    try:
        for tr_idx, val_idx in skf.split(X_raw, y):
            X_tr, X_val = X_raw.iloc[tr_idx], X_raw.iloc[val_idx]
            y_tr, y_val = y[tr_idx], y[val_idx]

            # ì „ì²´ íŒŒì´í”„ë¼ì¸ í•™ìŠµ
            pipe.fit(X_tr, y_tr)

            # validation ì˜ˆì¸¡
            y_prob = pipe.predict_proba(X_val)[:, 1]
            y_pred = (y_prob >= threshold).astype(int)
            f2 = fbeta_score(y_val, y_pred, beta=2)
            f2_scores.append(f2)

        mean_f2 = np.mean(f2_scores)
        print(f"Trial {trial.number} | F2 = {mean_f2:.4f} | th={threshold:.2f}")
        return mean_f2

    except Exception as e:
        print(f"âš ï¸ Trial {trial.number} failed: {e}")
        return None


# -------------------------------
# 6ï¸âƒ£ Optuna ì‹¤í–‰ (ì§„í–‰ìƒí™© í‘œì‹œ)
# -------------------------------
study = optuna.create_study(direction="maximize", study_name="xgb_f2_opt")
for _ in tqdm(range(50), desc="Optuna Trials Progress"):
    study.optimize(objective, n_trials=1, catch=(Exception,))

best_params = study.best_params
best_value = study.best_value
best_threshold = best_params.pop("threshold")

print("\nâœ… Best F2:", best_value)
print("âœ… Best Threshold:", best_threshold)
print("âœ… Best Params:", best_params)

# -------------------------------
# 7ï¸âƒ£ ìµœì  ëª¨ë¸ í•™ìŠµ
# -------------------------------
final_model = ImbPipeline(steps=[
    ("fix", feature_fixer),
    ("ct", ct),
    ("smote", SMOTE(random_state=42)),
    ("clf", make_clf(best_params))
])

final_model.fit(X_raw, y)
print("âœ… Final model trained successfully")

# -------------------------------
# 8ï¸âƒ£ ëª¨ë¸ ë° ë©”íƒ€ë°ì´í„° ì €ì¥
# -------------------------------
os.makedirs("./models", exist_ok=True)
joblib.dump(final_model, "./models/fin_xgb_pipeline.pkl")

meta = {
    "best_f2": best_value,
    "best_threshold": best_threshold,
    "best_params": best_params,
}
with open("./models/fin_xgb_meta.json", "w") as f:
    json.dump(meta, f, indent=2)

print("âœ… ëª¨ë¸ ë° íŒŒë¼ë¯¸í„° ì €ì¥ ì™„ë£Œ.")



#################=======================================================================

import pandas as pd
import joblib
import json
from sklearn.metrics import (
    fbeta_score,
    precision_score,
    recall_score,
    accuracy_score,
    confusion_matrix,
    classification_report
)
import matplotlib.pyplot as plt
import seaborn as sns

# -------------------------------
# 1ï¸âƒ£ ëª¨ë¸ ë° ë©”íƒ€ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
# -------------------------------
model_path = './models/fin_xgb_pipeline.pkl'
meta_path = './models/fin_xgb_meta.json'

model = joblib.load(model_path)
with open(meta_path, 'r') as f:
    meta = json.load(f)

threshold = meta["best_threshold"]
print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ | threshold = {threshold:.3f}")

# -------------------------------
# 2ï¸âƒ£ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# -------------------------------
train = pd.read_csv('./data/fin_train.csv')
test = pd.read_csv('./data/fin_test_kf.csv')

X_train = train.drop(columns=['passorfail'])
y_train = train['passorfail'].values

if 'passorfail' in test.columns:
    X_test = test.drop(columns=['passorfail'])
    y_test = test['passorfail'].values
else:
    X_test = test.copy()
    y_test = None

# -------------------------------
# 3ï¸âƒ£ ì˜ˆì¸¡ í•¨ìˆ˜ ì •ì˜
# -------------------------------
def evaluate_model(model, X, y, threshold, dataset_name="data"):
    y_prob = model.predict_proba(X)[:, 1]
    y_pred = (y_prob >= threshold).astype(int)

    precision = precision_score(y, y_pred)
    recall = recall_score(y, y_pred)
    f2 = fbeta_score(y, y_pred, beta=2)
    acc = accuracy_score(y, y_pred)
    cm = confusion_matrix(y, y_pred)

    print(f"\nğŸ“Š [{dataset_name}] ì„±ëŠ¥ ìš”ì•½")
    print(f"Accuracy  : {acc:.4f}")
    print(f"Precision : {precision:.4f}")
    print(f"Recall    : {recall:.4f}")
    print(f"F2-score  : {f2:.4f}")
    print("\ní˜¼ë™í–‰ë ¬:")
    print(cm)
    print("\nìƒì„¸ ë¦¬í¬íŠ¸:")
    print(classification_report(y, y_pred, digits=4))

    # í˜¼ë™í–‰ë ¬ ì‹œê°í™”
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f"Confusion Matrix - {dataset_name}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

    return {"acc": acc, "precision": precision, "recall": recall, "f2": f2}


# -------------------------------
# 4ï¸âƒ£ Train/Test í‰ê°€
# -------------------------------
train_result = evaluate_model(model, X_train, y_train, threshold, "Train")

if y_test is not None:
    test_result = evaluate_model(model, X_test, y_test, threshold, "Test")
else:
    print("\nâš ï¸ Test ë°ì´í„°ì— passorfail ì»¬ëŸ¼ì´ ì—†ì–´ í‰ê°€ ìƒëµë¨.")
    test_result = None

# -------------------------------
# 5ï¸âƒ£ ë¹„êµ ìš”ì•½ ì¶œë ¥
# -------------------------------
if test_result is not None:
    print("\nğŸ“ˆ Train vs Test ì„±ëŠ¥ ë¹„êµ")
    compare_df = pd.DataFrame({
        "Metric": ["Accuracy", "Precision", "Recall", "F2-score"],
        "Train": [
            train_result["acc"],
            train_result["precision"],
            train_result["recall"],
            train_result["f2"],
        ],
        "Test": [
            test_result["acc"],
            test_result["precision"],
            test_result["recall"],
            test_result["f2"],
        ],
    })
    print(compare_df.round(4))

    # ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”
    compare_df_melted = compare_df.melt(id_vars="Metric", var_name="Dataset", value_name="Score")
    plt.figure(figsize=(6, 4))
    sns.barplot(data=compare_df_melted, x="Metric", y="Score", hue="Dataset")
    plt.title("Train vs Test Performance Comparison")
    plt.ylim(0, 1)
    plt.show()
